
[34m[1mAMP: [39m[22mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...
[34m[1mAMP: [39m[22mchecks passed ✅
[34m[1mtrain: [39m[22mScanning /home/ashmitbhattarai/Codes/face_detection_model_family/data/images/valid/labels.cache... 130 images, 0 backgrounds, 0 corrupt: 100%|██████████| 130/130 [00:00<?, ?it/s]
[34m[1mtrain: [39m[22mWARNING ⚠️ /home/ashmitbhattarai/Codes/face_detection_model_family/data/images/valid/images/1c122de3-20221024_175221.jpg: corrupt JPEG restored and saved
[34m[1mtrain: [39m[22mWARNING ⚠️ /home/ashmitbhattarai/Codes/face_detection_model_family/data/images/valid/images/590527f0-20221024_175618.jpg: corrupt JPEG restored and saved
[34m[1mtrain: [39m[22mWARNING ⚠️ /home/ashmitbhattarai/Codes/face_detection_model_family/data/images/valid/images/592d3525-20221024_175453.jpg: corrupt JPEG restored and saved
[34m[1mtrain: [39m[22mWARNING ⚠️ /home/ashmitbhattarai/Codes/face_detection_model_family/data/images/valid/images/73cbe3fe-20221203_183133.jpg: corrupt JPEG restored and saved
[34m[1mtrain: [39m[22mWARNING ⚠️ /home/ashmitbhattarai/Codes/face_detection_model_family/data/images/valid/images/d74f42ab-20221024_175457.jpg: corrupt JPEG restored and saved
[34m[1mtrain: [39m[22mWARNING ⚠️ /home/ashmitbhattarai/Codes/face_detection_model_family/data/images/valid/images/da0372b0-20221203_183308.jpg: corrupt JPEG restored and saved
[34m[1mtrain: [39m[22mWARNING ⚠️ /home/ashmitbhattarai/Codes/face_detection_model_family/data/images/valid/images/eaefa5ca-20221203_183126.jpg: corrupt JPEG restored and saved
[34m[1mval: [39m[22mScanning /home/ashmitbhattarai/Codes/face_detection_model_family/data/images/valid/labels.cache... 130 images, 0 backgrounds, 0 corrupt: 100%|██████████| 130/130 [00:00<?, ?it/s]
[34m[1mtrain: [39m[22mWARNING ⚠️ /home/ashmitbhattarai/Codes/face_detection_model_family/data/images/valid/images/1c122de3-20221024_175221.jpg: corrupt JPEG restored and saved
[34m[1mtrain: [39m[22mWARNING ⚠️ /home/ashmitbhattarai/Codes/face_detection_model_family/data/images/valid/images/590527f0-20221024_175618.jpg: corrupt JPEG restored and saved
[34m[1mtrain: [39m[22mWARNING ⚠️ /home/ashmitbhattarai/Codes/face_detection_model_family/data/images/valid/images/592d3525-20221024_175453.jpg: corrupt JPEG restored and saved
[34m[1mtrain: [39m[22mWARNING ⚠️ /home/ashmitbhattarai/Codes/face_detection_model_family/data/images/valid/images/73cbe3fe-20221203_183133.jpg: corrupt JPEG restored and saved
[34m[1mtrain: [39m[22mWARNING ⚠️ /home/ashmitbhattarai/Codes/face_detection_model_family/data/images/valid/images/d74f42ab-20221024_175457.jpg: corrupt JPEG restored and saved
[34m[1mtrain: [39m[22mWARNING ⚠️ /home/ashmitbhattarai/Codes/face_detection_model_family/data/images/valid/images/da0372b0-20221203_183308.jpg: corrupt JPEG restored and saved
[34m[1mtrain: [39m[22mWARNING ⚠️ /home/ashmitbhattarai/Codes/face_detection_model_family/data/images/valid/images/eaefa5ca-20221203_183126.jpg: corrupt JPEG restored and saved
Plotting labels to runs/detect/train/labels.jpg...
[34m[1moptimizer:[39m[22m AdamW(lr=0.000833, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005625000000000001), 63 bias(decay=0.0)
Image sizes 640 train, 640 val
Using 1 dataloader workers
Logging results to [1mruns/detect/train
Starting training for 300 epochs...
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
      1/300      5.69G      2.436      10.81      2.298         41        640: 100%|██████████| 6/6 [00:02<00:00,  2.25it/s]
/home/ashmitbhattarai/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  4.89it/s]
                   all        130        292          0          0          0          0
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
      2/300      5.84G      2.377      9.907      2.243         29        640: 100%|██████████| 6/6 [00:01<00:00,  5.41it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  5.31it/s]
                   all        130        292      0.184     0.0547     0.0549     0.0171
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
      3/300      5.78G      1.766      3.939      1.621         31        640: 100%|██████████| 6/6 [00:01<00:00,  4.84it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  4.09it/s]
                   all        130        292      0.354      0.386      0.399      0.238
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
      4/300      5.79G      1.488      2.988      1.483         24        640: 100%|██████████| 6/6 [00:01<00:00,  5.40it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  4.01it/s]
                   all        130        292      0.576      0.603      0.606      0.382
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
      5/300      5.82G      1.457      2.295      1.338         56        640: 100%|██████████| 6/6 [00:01<00:00,  5.39it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.94it/s]
                   all        130        292      0.745      0.521      0.613      0.398
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
      6/300      5.78G      1.389      2.011      1.293         38        640: 100%|██████████| 6/6 [00:01<00:00,  5.26it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  4.08it/s]
                   all        130        292      0.691       0.63      0.704      0.485
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
      7/300      5.85G      1.341      1.818      1.294         21        640: 100%|██████████| 6/6 [00:01<00:00,  5.58it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  4.25it/s]
                   all        130        292      0.763      0.621      0.724      0.499
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
      8/300      5.79G      1.196      1.722      1.236         21        640: 100%|██████████| 6/6 [00:01<00:00,  5.58it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  4.15it/s]
                   all        130        292      0.814      0.653      0.755        0.5
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
      9/300      5.84G      1.263      1.482      1.202         36        640: 100%|██████████| 6/6 [00:01<00:00,  5.13it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.95it/s]
                   all        130        292      0.675      0.738      0.762      0.508
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
     10/300      5.58G      1.183      1.423      1.197         37        640: 100%|██████████| 6/6 [00:01<00:00,  5.11it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.93it/s]
                   all        130        292      0.774      0.679       0.76      0.548
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
     11/300      5.85G      1.196      1.379      1.199         33        640: 100%|██████████| 6/6 [00:01<00:00,  5.20it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.95it/s]
                   all        130        292      0.757      0.664      0.744      0.516
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
     12/300      5.79G      1.202      1.331      1.243         27        640: 100%|██████████| 6/6 [00:01<00:00,  5.59it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  4.18it/s]
                   all        130        292      0.631      0.462      0.522      0.368
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
     13/300      5.69G      1.179      1.239      1.215         24        640: 100%|██████████| 6/6 [00:01<00:00,  5.25it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  4.00it/s]
                   all        130        292      0.738      0.631      0.745      0.518
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
     14/300      5.79G      1.158      1.118      1.172         26        640: 100%|██████████| 6/6 [00:01<00:00,  5.51it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.92it/s]
                   all        130        292      0.828      0.599      0.751      0.549
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
     15/300      5.68G      1.159     0.9919      1.148         43        640: 100%|██████████| 6/6 [00:01<00:00,  4.91it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.94it/s]
                   all        130        292       0.87      0.683      0.799      0.574
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
     16/300      5.83G      1.157      1.001      1.159         60        640: 100%|██████████| 6/6 [00:01<00:00,  5.60it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.99it/s]
                   all        130        292      0.799      0.613      0.706       0.52
     17/300      5.79G      1.122     0.9625       1.16         28        640: 100%|██████████| 6/6 [00:01<00:00,  5.28it/s]  3.99it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.60it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.28it/s]  3.99it/s]
     18/300      5.79G      1.128      1.004      1.242         72        640:  50%|█████     | 3/6 [00:00<00:00,  5.12it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.28it/s]  3.99it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
     19/300      5.76G      1.015      1.089      1.169         63        640:  17%|█▋        | 1/6 [00:00<00:00,  5.27it/s]
                   all        130        292      0.902      0.674      0.825      0.582██████| 6/6 [00:01<00:00,  5.28it/s]  3.99it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].99it/s]
     21/300      5.77G      1.136      1.082      1.151         90        640:  50%|█████     | 3/6 [00:00<00:00,  5.12it/s]  4.13it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.64it/s]  4.13it/s]
  0%|          | 0/6 [00:00<?, ?it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.64it/s]  4.13it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.64it/s]  4.13it/s]
                   all        130        292      0.966      0.756      0.869      0.642██████| 6/6 [00:01<00:00,  5.64it/s]  4.13it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.84it/s]
     25/300      5.58G      1.071      0.794      1.079         78        640: 100%|██████████| 6/6 [00:01<00:00,  4.97it/s]  3.84it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  4.97it/s]  3.84it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  4.97it/s]  3.84it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  4.97it/s]  3.84it/s]
                   all        130        292       0.96      0.818      0.899       0.69██████| 6/6 [00:01<00:00,  4.97it/s]  3.84it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.72it/s]
     29/300      5.77G      1.024      0.768       1.12         36        640: 100%|██████████| 6/6 [00:01<00:00,  5.65it/s]  3.72it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.65it/s]  3.72it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.65it/s]  3.72it/s]
                   all        130        292      0.955       0.84      0.916      0.717██████| 6/6 [00:01<00:00,  5.65it/s]  3.72it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.20it/s]
     33/300      5.82G      1.058     0.6932      1.078         85        640:  83%|████████▎ | 5/6 [00:01<00:00,  5.04it/s]  3.93it/s]
     33/300      5.82G      1.035     0.6935      1.062         56        640: 100%|██████████| 6/6 [00:01<00:00,  5.31it/s]  3.93it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.31it/s]  3.93it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.31it/s]  3.93it/s]
                   all        130        292      0.933      0.832      0.907      0.706██████| 6/6 [00:01<00:00,  5.31it/s]  3.93it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.76it/s]
     37/300      5.78G      1.014     0.6914      1.068         63        640: 100%|██████████| 6/6 [00:01<00:00,  5.60it/s]  3.76it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.60it/s]  3.76it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.60it/s]  3.76it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.60it/s]  3.76it/s]
                   all        130        292      0.993      0.926      0.959      0.772██████| 6/6 [00:01<00:00,  5.60it/s]  3.76it/s]
  0%|          | 0/6 [00:00<?, ?it/s]stances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.72it/s]
     41/300      5.79G     0.9637     0.6627      1.071         47        640: 100%|██████████| 6/6 [00:01<00:00,  5.63it/s]  3.72it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.63it/s]  3.72it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.63it/s]  3.72it/s]
                   all        130        292      0.974      0.898      0.944       0.77██████| 6/6 [00:01<00:00,  5.63it/s]  3.72it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.70it/s]
     45/300      5.77G     0.8705     0.5936      1.063         36        640: 100%|██████████| 6/6 [00:01<00:00,  5.64it/s]  3.70it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.64it/s]  3.70it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.64it/s]  3.70it/s]
                   all        130        292      0.994      0.947      0.971      0.804██████| 6/6 [00:01<00:00,  5.64it/s]  3.70it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].70it/s]
     49/300      5.77G     0.8714     0.5705      1.008        105        640:  33%|███▎      | 2/6 [00:00<00:00,  5.07it/s]  3.63it/s]
     49/300      5.79G     0.8989     0.5797      1.024         45        640: 100%|██████████| 6/6 [00:01<00:00,  5.44it/s]  3.63it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.44it/s]  3.63it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.44it/s]  3.63it/s]
                   all        130        292      0.965      0.888      0.923      0.774██████| 6/6 [00:01<00:00,  5.44it/s]  3.63it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.99it/s]
     53/300      5.79G     0.9115      0.628      1.036         59        640:  50%|█████     | 3/6 [00:00<00:00,  5.25it/s]  3.42it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.79it/s]  3.42it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.79it/s]  3.42it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.79it/s]  3.42it/s]
                   all        130        292      0.973      0.928      0.959        0.8██████| 6/6 [00:01<00:00,  5.79it/s]  3.42it/s]
  0%|          | 0/6 [00:00<?, ?it/s]stances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.49it/s]
     57/300      5.81G     0.8588     0.6184      1.043         49        640: 100%|██████████| 6/6 [00:01<00:00,  5.51it/s]  3.49it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.51it/s]  3.49it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.51it/s]  3.49it/s]
                   all        130        292      0.998      0.979      0.985      0.832██████| 6/6 [00:01<00:00,  5.51it/s]  3.49it/s]
                   all        130        292      0.998      0.979      0.985      0.832██████| 6/6 [00:01<00:00,  5.51it/s]  3.49it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.17it/s]
     61/300      5.69G     0.8149     0.5635     0.9878         37        640: 100%|██████████| 6/6 [00:01<00:00,  5.04it/s]  3.17it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.04it/s]  3.17it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.04it/s]  3.17it/s]
                   all        130        292      0.973      0.943      0.966      0.827██████| 6/6 [00:01<00:00,  5.04it/s]  3.17it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.57it/s]
     65/300      5.83G     0.8093     0.5493      1.026         31        640: 100%|██████████| 6/6 [00:01<00:00,  5.84it/s]  3.98it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.84it/s]  3.98it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.84it/s]  3.98it/s]
                   all        130        292      0.985      0.944       0.97      0.829██████| 6/6 [00:01<00:00,  5.84it/s]  3.98it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.40it/s]
     69/300      5.81G     0.7998     0.5366     0.9976         86        640: 100%|██████████| 6/6 [00:01<00:00,  5.45it/s]  3.81it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.45it/s]  3.81it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.45it/s]  3.81it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.45it/s]  3.81it/s]
                   all        130        292      0.992      0.988      0.988      0.838██████| 6/6 [00:01<00:00,  5.45it/s]  3.81it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.22it/s]
     73/300      5.77G     0.7444     0.4731      0.953         59        640: 100%|██████████| 6/6 [00:01<00:00,  5.13it/s]  3.22it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.13it/s]  3.22it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.13it/s]  3.22it/s]
                   all        130        292      0.996      0.981      0.986       0.86██████| 6/6 [00:01<00:00,  5.13it/s]  3.22it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].22it/s]
  0%|          | 0/6 [00:00<?, ?it/s]stances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.67it/s]
     77/300      5.78G      0.776     0.5099     0.9997         27        640: 100%|██████████| 6/6 [00:01<00:00,  5.80it/s]  3.67it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.80it/s]  3.67it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.80it/s]  3.67it/s]
                   all        130        292      0.992      0.983      0.987      0.867██████| 6/6 [00:01<00:00,  5.80it/s]  3.67it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.27it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.68it/s]
     81/300      5.77G     0.7408     0.5284     0.9826         36        640: 100%|██████████| 6/6 [00:01<00:00,  5.48it/s]  3.68it/s]
     81/300      5.77G     0.7408     0.5284     0.9826         36        640: 100%|██████████| 6/6 [00:01<00:00,  5.48it/s]  3.68it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.48it/s]  3.68it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.48it/s]  3.68it/s]
                   all        130        292      0.997      0.978      0.985      0.867██████| 6/6 [00:01<00:00,  5.48it/s]  3.68it/s]
  0%|          | 0/6 [00:00<?, ?it/s]stances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.24it/s]
     85/300      5.85G     0.8602     0.5394      0.978         34        640: 100%|██████████| 6/6 [00:01<00:00,  5.19it/s]  3.24it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.19it/s]  3.24it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.19it/s]  3.24it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.19it/s]  3.24it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].24it/s]
  0%|          | 0/6 [00:00<?, ?it/s]stances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.71it/s]
     89/300      5.67G     0.7166     0.4742     0.9517         31        640: 100%|██████████| 6/6 [00:01<00:00,  5.44it/s]  3.71it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.44it/s]  3.71it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.44it/s]  3.71it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.44it/s]  3.71it/s]
                   all        130        292      0.979      0.979      0.982      0.876██████| 6/6 [00:01<00:00,  5.44it/s]  3.71it/s]
     93/300      5.76G     0.7487     0.5061      1.006         75        640:  17%|█▋        | 1/6 [00:00<00:01,  4.85it/s]  3.19it/s]
     93/300      5.79G     0.7541     0.5155     0.9854         51        640: 100%|██████████| 6/6 [00:01<00:00,  5.18it/s]  3.19it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.18it/s]  3.19it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.18it/s]  3.19it/s]
                   all        130        292      0.996      0.982      0.987      0.883██████| 6/6 [00:01<00:00,  5.18it/s]  3.19it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.00it/s]
     97/300      5.79G     0.7916     0.4615      0.982         42        640: 100%|██████████| 6/6 [00:01<00:00,  5.76it/s]  3.65it/s]
     97/300      5.79G     0.7916     0.4615      0.982         42        640: 100%|██████████| 6/6 [00:01<00:00,  5.76it/s]  3.65it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.76it/s]  3.65it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.76it/s]  3.65it/s]
                   all        130        292      0.995      0.989       0.99      0.889██████| 6/6 [00:01<00:00,  5.76it/s]  3.65it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.63it/s]
    101/300      5.78G     0.6557     0.4303     0.9498         36        640: 100%|██████████| 6/6 [00:01<00:00,  5.83it/s]  3.63it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.83it/s]  3.63it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.83it/s]  3.63it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.83it/s]  3.63it/s]
                   all        130        292      0.997      0.989       0.99      0.908██████| 6/6 [00:01<00:00,  5.83it/s]  3.63it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.71it/s]
    105/300      5.78G     0.6875     0.4416     0.9635         40        640: 100%|██████████| 6/6 [00:01<00:00,  5.81it/s]  3.71it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.81it/s]  3.71it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.81it/s]  3.71it/s]
                   all        130        292      0.996      0.989       0.99      0.909██████| 6/6 [00:01<00:00,  5.81it/s]  3.71it/s]
                   all        130        292      0.996      0.989       0.99      0.909██████| 6/6 [00:01<00:00,  5.81it/s]  3.71it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.55it/s]
    109/300      5.78G      0.646     0.4332     0.9439         24        640: 100%|██████████| 6/6 [00:01<00:00,  5.80it/s]  3.55it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.80it/s]  3.55it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.80it/s]  3.55it/s]
                   all        130        292      0.998      0.989       0.99      0.899██████| 6/6 [00:01<00:00,  5.80it/s]  3.55it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.52it/s]
    113/300      5.77G     0.6324     0.4327     0.9338         46        640: 100%|██████████| 6/6 [00:01<00:00,  5.77it/s]  3.52it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.77it/s]  3.52it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.77it/s]  3.52it/s]
                   all        130        292          1      0.989       0.99      0.901██████| 6/6 [00:01<00:00,  5.77it/s]  3.52it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.07it/s]
    117/300      5.76G     0.5756     0.4121     0.9237         64        640:  17%|█▋        | 1/6 [00:00<00:00,  5.41it/s]  3.69it/s]
    117/300      5.79G     0.6204     0.4116     0.9035         66        640: 100%|██████████| 6/6 [00:01<00:00,  5.81it/s]  3.69it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.81it/s]  3.69it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.81it/s]  3.69it/s]
                   all        130        292          1      0.989       0.99      0.915██████| 6/6 [00:01<00:00,  5.81it/s]  3.69it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.67it/s]
    121/300       5.9G     0.6434     0.4141      0.927         51        640: 100%|██████████| 6/6 [00:01<00:00,  5.77it/s]  3.67it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.77it/s]  3.67it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.77it/s]  3.67it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.77it/s]  3.67it/s]
                   all        130        292          1      0.988      0.989      0.917██████| 6/6 [00:01<00:00,  5.77it/s]  3.67it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.69it/s]
    125/300      5.79G     0.5881     0.3843      0.908         58        640: 100%|██████████| 6/6 [00:01<00:00,  5.82it/s]  3.69it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.82it/s]  3.69it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.82it/s]  3.69it/s]
                   all        130        292          1      0.989       0.99      0.923██████| 6/6 [00:01<00:00,  5.82it/s]  3.69it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.06it/s]
    129/300      5.79G     0.5588     0.3818     0.9189         87        640:  67%|██████▋   | 4/6 [00:00<00:00,  5.29it/s]  3.65it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.77it/s]  3.65it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.77it/s]  3.65it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.77it/s]  3.65it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].65it/s]
    133/300      5.79G      0.589     0.3928     0.9118         90        640:  50%|█████     | 3/6 [00:00<00:00,  5.15it/s]  3.62it/s]
    133/300      5.79G     0.5896     0.3907     0.9032         29        640: 100%|██████████| 6/6 [00:01<00:00,  5.74it/s]  3.62it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.74it/s]  3.62it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.74it/s]  3.62it/s]
                   all        130        292          1      0.989       0.99      0.928██████| 6/6 [00:01<00:00,  5.74it/s]  3.62it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.20it/s]
    137/300      5.91G     0.5671     0.3752     0.8862         43        640: 100%|██████████| 6/6 [00:01<00:00,  5.18it/s]  3.20it/s]
    137/300      5.91G     0.5671     0.3752     0.8862         43        640: 100%|██████████| 6/6 [00:01<00:00,  5.18it/s]  3.20it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.18it/s]  3.20it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.18it/s]  3.20it/s]
                   all        130        292      0.999      0.989       0.99      0.926██████| 6/6 [00:01<00:00,  5.18it/s]  3.20it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.93it/s]
    141/300      5.81G     0.6085     0.4178     0.9319         57        640: 100%|██████████| 6/6 [00:01<00:00,  5.20it/s]  2.93it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.20it/s]  2.93it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.20it/s]  2.93it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.20it/s]  2.93it/s]
                   all        130        292          1      0.989       0.99      0.924██████| 6/6 [00:01<00:00,  5.20it/s]  2.93it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.51it/s]
    145/300      5.81G     0.5727     0.3741     0.9099         44        640: 100%|██████████| 6/6 [00:01<00:00,  5.61it/s]  3.51it/s]
    145/300      5.81G     0.5727     0.3741     0.9099         44        640: 100%|██████████| 6/6 [00:01<00:00,  5.61it/s]  3.51it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.61it/s]  3.51it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.61it/s]  3.51it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.61it/s]  3.51it/s]
                   all        130        292          1      0.989       0.99       0.94██████| 6/6 [00:01<00:00,  5.61it/s]  3.51it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.92it/s]
    149/300      5.79G     0.5144     0.3422      0.884        119        640:  67%|██████▋   | 4/6 [00:00<00:00,  5.37it/s]  2.92it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.80it/s]  2.92it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.80it/s]  2.92it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.80it/s]  2.92it/s]
                   all        130        292          1      0.989       0.99      0.933██████| 6/6 [00:01<00:00,  5.80it/s]  2.92it/s]
    153/300      5.76G     0.5606     0.3895     0.9157         95        640:  17%|█▋        | 1/6 [00:00<00:01,  4.76it/s]  3.23it/s]
    153/300      5.79G     0.5259     0.3599     0.8968         30        640: 100%|██████████| 6/6 [00:01<00:00,  5.17it/s]  3.23it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.17it/s]  3.23it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.17it/s]  3.23it/s]
                   all        130        292      0.997      0.989       0.99      0.937██████| 6/6 [00:01<00:00,  5.17it/s]  3.23it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].23it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].23it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].23it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.80it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.80it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.80it/s]
                   all        130        292          1      0.989       0.99      0.943:  33%|███▎      | 1/3 [00:00<00:00,  2.80it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.90it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.90it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.90it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.90it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.90it/s]
                   all        130        292      0.999      0.989       0.99      0.953:  33%|███▎      | 1/3 [00:00<00:00,  2.90it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.43it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.43it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.43it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.45it/s]
    170/300      5.67G     0.4948     0.3527     0.8772         70        640:  83%|████████▎ | 5/6 [00:01<00:00,  4.95it/s]  3.45it/s]
    170/300      5.67G     0.4948     0.3527     0.8772         70        640:  83%|████████▎ | 5/6 [00:01<00:00,  4.95it/s]  3.45it/s]
                   all        130        292          1      0.989       0.99      0.954████▎ | 5/6 [00:01<00:00,  4.95it/s]  3.45it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.07it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.07it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.07it/s]
                   all        130        292          1      0.991      0.991      0.954:  67%|██████▋   | 2/3 [00:00<00:00,  3.07it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].07it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].07it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].07it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].07it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].07it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].07it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].07it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].07it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].07it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].07it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].07it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].07it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].07it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].07it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.07it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.07it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.07it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.09it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.09it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.09it/s]
                   all        130        292          1      0.989       0.99      0.964:  67%|██████▋   | 2/3 [00:00<00:00,  3.09it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.87it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.87it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.87it/s]
                   all        130        292          1      0.989       0.99      0.959:  33%|███▎      | 1/3 [00:00<00:00,  2.87it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].87it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].87it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].87it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.66it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.66it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.66it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.71it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.71it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.71it/s]
                   all        130        292          1      0.989       0.99      0.965:  33%|███▎      | 1/3 [00:00<00:00,  2.71it/s]
                   all        130        292          1      0.989       0.99      0.965:  33%|███▎      | 1/3 [00:00<00:00,  2.71it/s]
                   all        130        292          1      0.989       0.99      0.965:  33%|███▎      | 1/3 [00:00<00:00,  2.71it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.88it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.88it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.88it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.90it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.90it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.90it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.89it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.89it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.89it/s]
                   all        130        292          1      0.989       0.99      0.966:  33%|███▎      | 1/3 [00:00<00:00,  2.89it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.87it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.87it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.87it/s]
                   all        130        292          1      0.989       0.99      0.968:  33%|███▎      | 1/3 [00:00<00:00,  2.87it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.95it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.95it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.95it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.95it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.95it/s]
                   all        130        292          1      0.989       0.99      0.969:  33%|███▎      | 1/3 [00:00<00:00,  2.95it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].95it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].95it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].95it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].95it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].95it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.96it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.96it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.96it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.87it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.87it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.87it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].87it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].87it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].87it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.92it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.92it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.92it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.78it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.78it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.78it/s]
                   all        130        292          1      0.989       0.99      0.973:  67%|██████▋   | 2/3 [00:00<00:00,  2.78it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.93it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.93it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.93it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.84it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.84it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.84it/s]
                   all        130        292          1      0.989       0.99      0.975:  67%|██████▋   | 2/3 [00:00<00:00,  2.84it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].84it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].84it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].84it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].84it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].84it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.96it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.96it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.96it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.96it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.96it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.96it/s]
                   all        130        292          1      0.989       0.99      0.976:  33%|███▎      | 1/3 [00:00<00:00,  2.96it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].96it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].96it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].96it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].96it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].96it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].96it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.52it/s]
    251/300      5.79G     0.3675     0.2603     0.8508         30        640: 100%|██████████| 6/6 [00:01<00:00,  5.49it/s]  3.52it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.49it/s]  3.52it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.49it/s]  3.52it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.76it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.76it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.76it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.76it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.76it/s]
                   all        130        292          1      0.991      0.991       0.98:  33%|███▎      | 1/3 [00:00<00:00,  2.76it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].76it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].76it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].76it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.87it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.87it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.87it/s]
                   all        130        292          1      0.989       0.99      0.982:  67%|██████▋   | 2/3 [00:00<00:00,  2.87it/s]
                   all        130        292          1      0.989       0.99      0.982:  67%|██████▋   | 2/3 [00:00<00:00,  2.87it/s]
                   all        130        292          1      0.989       0.99      0.982:  67%|██████▋   | 2/3 [00:00<00:00,  2.87it/s]
                   all        130        292          1      0.991      0.991      0.983:  67%|██████▋   | 2/3 [00:00<00:00,  2.87it/s]
                   all        130        292          1      0.991      0.991      0.983:  67%|██████▋   | 2/3 [00:00<00:00,  2.87it/s]
                   all        130        292          1      0.991      0.991      0.983:  67%|██████▋   | 2/3 [00:00<00:00,  2.87it/s]
                   all        130        292          1      0.991      0.991      0.982:  67%|██████▋   | 2/3 [00:00<00:00,  2.87it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.88it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.88it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.88it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.94it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.94it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.94it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.94it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.94it/s]
                   all        130        292          1      0.991      0.991      0.985:  33%|███▎      | 1/3 [00:00<00:00,  2.94it/s]
                   all        130        292          1      0.991      0.991      0.985:  33%|███▎      | 1/3 [00:00<00:00,  2.94it/s]
                   all        130        292          1      0.991      0.991      0.985:  33%|███▎      | 1/3 [00:00<00:00,  2.94it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.87it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.87it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.87it/s]
                   all        130        292          1      0.991      0.991      0.983:  33%|███▎      | 1/3 [00:00<00:00,  2.87it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.88it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.88it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.88it/s]
                   all        130        292          1      0.991      0.991      0.984:  33%|███▎      | 1/3 [00:00<00:00,  2.88it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.84it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.84it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.84it/s]
                   all        130        292          1      0.991      0.991      0.985:  33%|███▎      | 1/3 [00:00<00:00,  2.84it/s]
                   all        130        292          1      0.991      0.991      0.985:  33%|███▎      | 1/3 [00:00<00:00,  2.84it/s]
                   all        130        292          1      0.991      0.991      0.985:  33%|███▎      | 1/3 [00:00<00:00,  2.84it/s]
                   all        130        292          1      0.991      0.991      0.985:  33%|███▎      | 1/3 [00:00<00:00,  2.84it/s]
                   all        130        292          1      0.991      0.991      0.985:  33%|███▎      | 1/3 [00:00<00:00,  2.84it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.09it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.09it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.09it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].09it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].09it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].09it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.42it/s]
    289/300       5.8G     0.3054     0.2399     0.8395         24        640: 100%|██████████| 6/6 [00:01<00:00,  5.17it/s]  3.42it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.17it/s]  3.42it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.17it/s]  3.42it/s]
                   all        130        292          1      0.991      0.991      0.984██████| 6/6 [00:01<00:00,  5.17it/s]  3.42it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].42it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].42it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].42it/s]
                   all        130        292          1      0.991      0.991      0.986:   0%|          | 0/3 [00:00<?, ?it/s].42it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].42it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].42it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].42it/s]
                   all        130        292          1      0.991      0.991      0.985:   0%|          | 0/3 [00:00<?, ?it/s].42it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].42it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].42it/s]
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].42it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.50it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.50it/s]
Model summary (fused): 168 layers, 11128680 parameters, 0 gradients     mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.50it/s]
Model summary (fused): 168 layers, 11128680 parameters, 0 gradients     mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.50it/s]
Results saved to [1mruns/detect/train[22m        20          1          1      0.995      0.995:  33%|███▎      | 1/3 [00:00<00:00,  2.50it/s]
Results saved to [1mruns/detect/train[22m        20          1          1      0.995      0.995:  33%|███▎      | 1/3 [00:00<00:00,  2.50it/s]
Results saved to [1mruns/detect/train[22m        20          1          1      0.995      0.995:  33%|███▎      | 1/3 [00:00<00:00,  2.50it/s]
[34m[1mtrain: [39m[22mWARNING ⚠️ /home/ashmitbhattarai/Codes/face_detection_model_family/data/images/valid/images/eaefa5ca-20221203_183126.jpg: corrupt JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Sizea/images/valid/images/eaefa5ca-20221203_183126.jpg: corrupt JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Sizea/images/valid/images/eaefa5ca-20221203_183126.jpg: corrupt JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Sizea/images/valid/images/eaefa5ca-20221203_183126.jpg: corrupt JPEG restored and saved
                   all        130        292          1      0.989       0.99      0.982lid/images/eaefa5ca-20221203_183126.jpg: corrupt JPEG restored and saved
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.28it/s]t JPEG restored and saved
      4/300      5.76G     0.3784     0.2664      0.861         71        640:  67%|██████▋   | 4/6 [00:00<00:00,  5.13it/s]  3.78it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.46it/s]  3.78it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.46it/s]  3.78it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.46it/s]  3.78it/s]t JPEG restored and saved
                   all        130        292          1      0.988      0.989      0.963██████| 6/6 [00:01<00:00,  5.46it/s]  3.78it/s]t JPEG restored and saved
      8/300      2.14G     0.3784     0.2764     0.8616         94        640:  17%|█▋        | 1/6 [00:00<00:01,  4.03it/s]  3.81it/s]t JPEG restored and saved
      8/300      5.74G     0.4185     0.2879     0.8614         21        640: 100%|██████████| 6/6 [00:01<00:00,  5.01it/s]  3.81it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.01it/s]  3.81it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.01it/s]  3.81it/s]t JPEG restored and saved
                   all        130        292          1      0.988      0.989      0.943██████| 6/6 [00:01<00:00,  5.01it/s]  3.81it/s]t JPEG restored and saved
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.70it/s]t JPEG restored and saved
     12/300      5.75G     0.4637     0.3297     0.8632         27        640: 100%|██████████| 6/6 [00:01<00:00,  5.46it/s]  3.70it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.46it/s]  3.70it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.46it/s]  3.70it/s]t JPEG restored and saved
                   all        130        292          1      0.969      0.981      0.931██████| 6/6 [00:01<00:00,  5.46it/s]  3.70it/s]t JPEG restored and saved
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.05it/s]t JPEG restored and saved
     16/300      5.76G     0.5362     0.3964      0.883         60        640: 100%|██████████| 6/6 [00:01<00:00,  5.42it/s]  3.51it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.42it/s]  3.51it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.42it/s]  3.51it/s]t JPEG restored and saved
                   all        130        292      0.994      0.961      0.974      0.898██████| 6/6 [00:01<00:00,  5.42it/s]  3.51it/s]t JPEG restored and saved
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].51it/s]t JPEG restored and saved
     20/300      5.82G     0.5578      0.405     0.9112        126        640:  33%|███▎      | 2/6 [00:00<00:00,  4.58it/s]  3.56it/s]t JPEG restored and saved
     20/300      5.82G      0.537     0.4217     0.9247         19        640: 100%|██████████| 6/6 [00:01<00:00,  5.33it/s]  3.56it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.33it/s]  3.56it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.33it/s]  3.56it/s]t JPEG restored and saved
                   all        130        292      0.987      0.973      0.984      0.913██████| 6/6 [00:01<00:00,  5.33it/s]  3.56it/s]t JPEG restored and saved
  0%|          | 0/6 [00:00<?, ?it/s]stances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.71it/s]t JPEG restored and saved
     24/300      5.68G     0.5644     0.4015     0.8728         28        640: 100%|██████████| 6/6 [00:01<00:00,  5.78it/s]  3.71it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.78it/s]  3.71it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.78it/s]  3.71it/s]t JPEG restored and saved
                   all        130        292      0.998      0.982      0.987      0.918██████| 6/6 [00:01<00:00,  5.78it/s]  3.71it/s]t JPEG restored and saved
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.00it/s]t JPEG restored and saved
     28/300      5.77G     0.5484     0.3968     0.9187         84        640:  67%|██████▋   | 4/6 [00:00<00:00,  4.95it/s]  3.06it/s]t JPEG restored and saved
     28/300      5.77G     0.5524     0.3908     0.9166         24        640: 100%|██████████| 6/6 [00:01<00:00,  5.33it/s]  3.06it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.33it/s]  3.06it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.33it/s]  3.06it/s]t JPEG restored and saved
                   all        130        292      0.998      0.976      0.984      0.918██████| 6/6 [00:01<00:00,  5.33it/s]  3.06it/s]t JPEG restored and saved
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.63it/s]t JPEG restored and saved
     32/300      5.58G     0.5463     0.3833     0.8851         21        640: 100%|██████████| 6/6 [00:01<00:00,  5.38it/s]  3.63it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.38it/s]  3.63it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.38it/s]  3.63it/s]t JPEG restored and saved
                   all        130        292          1      0.954      0.975      0.906██████| 6/6 [00:01<00:00,  5.38it/s]  3.63it/s]t JPEG restored and saved
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.87it/s]t JPEG restored and saved
     36/300       5.5G      0.552     0.4025     0.8906        111        640:  50%|█████     | 3/6 [00:00<00:00,  4.55it/s]  3.41it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.21it/s]  3.41it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.21it/s]  3.41it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.21it/s]  3.41it/s]t JPEG restored and saved
                   all        130        292          1       0.98      0.986      0.921██████| 6/6 [00:01<00:00,  5.21it/s]  3.41it/s]t JPEG restored and saved
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.36it/s]t JPEG restored and saved
     40/300      5.74G     0.5113     0.3712     0.9011         33        640: 100%|██████████| 6/6 [00:01<00:00,  5.52it/s]  3.36it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.52it/s]  3.36it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.52it/s]  3.36it/s]t JPEG restored and saved
                   all        130        292      0.976      0.903      0.948      0.888██████| 6/6 [00:01<00:00,  5.52it/s]  3.36it/s]t JPEG restored and saved
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.07it/s]t JPEG restored and saved
     44/300      5.76G     0.5163     0.3603     0.8885         74        640:  67%|██████▋   | 4/6 [00:00<00:00,  4.94it/s]  3.45it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.32it/s]  3.45it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.32it/s]  3.45it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.32it/s]  3.45it/s]t JPEG restored and saved
                   all        130        292      0.993      0.958      0.977      0.915██████| 6/6 [00:01<00:00,  5.32it/s]  3.45it/s]t JPEG restored and saved
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.30it/s]t JPEG restored and saved
     48/300      5.74G     0.5273     0.3652     0.9037         23        640: 100%|██████████| 6/6 [00:01<00:00,  5.51it/s]  3.30it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.51it/s]  3.30it/s]t JPEG restored and saved
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.51it/s]  3.30it/s]t JPEG restored and saved
                   all        130        292      0.994      0.963      0.978      0.929██████| 6/6 [00:01<00:00,  5.51it/s]  3.30it/s]t JPEG restored and saved
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.65it/s]t JPEG restored and saved
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.20it/s]t JPEG restored and saved
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  2.20it/s]t JPEG restored and saved
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.48it/s]t JPEG restored and saved
                samjhu        130         33          1          1      0.995      0.977: 100%|██████████| 3/3 [00:01<00:00,  2.58it/s]t JPEG restored and saved
                samjhu        130         33          1          1      0.995      0.977: 100%|██████████| 3/3 [00:01<00:00,  2.58it/s]t JPEG restored and saved
                samjhu        130         33          1          1      0.995      0.977: 100%|██████████| 3/3 [00:01<00:00,  2.58it/s]t JPEG restored and saved
image 1/1 /home/ashmitbhattarai/Codes/face_detection_model_family/data/images/test/IMG-2076.jpg: 480x640 1 ashmit, 1 glasses, 2 rameshs, 2 samjhus, 4.0msd saved
Speed: 1.7ms preprocess, 4.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640): 480x640 1 ashmit, 1 glasses, 2 rameshs, 2 samjhus, 4.0msd saved
Speed: 1.7ms preprocess, 4.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640): 480x640 1 ashmit, 1 glasses, 2 rameshs, 2 samjhus, 4.0msd saved
[34m[1mtrain: [39m[22mWARNING ⚠️ /home/ashmitbhattarai/Codes/face_detection_model_family/data/images/valid/images/d74f42ab-20221024_175457.jpg: corrupt JPEG restored and saved
Starting training for 300 epochs...tum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005625000000000001), 63 bias(decay=0.0)ored and saved
/home/ashmitbhattarai/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
/home/ashmitbhattarai/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
/home/ashmitbhattarai/miniconda3/envs/torch_cuda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292      0.184     0.0547     0.0562     0.0177m/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  4.07it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      4/300      5.73G      1.488      2.988      1.483         24        640: 100%|██████████| 6/6 [00:01<00:00,  5.19it/s]  4.07it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      4/300      5.73G      1.488      2.988      1.483         24        640: 100%|██████████| 6/6 [00:01<00:00,  5.19it/s]  4.07it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.19it/s]  4.07it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.19it/s]  4.07it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.19it/s]  4.07it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292      0.692      0.629      0.701      0.486██████| 6/6 [00:01<00:00,  5.19it/s]  4.07it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292      0.692      0.629      0.701      0.486██████| 6/6 [00:01<00:00,  5.19it/s]  4.07it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  4.32it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      8/300      5.67G      1.212      1.719      1.254         81        640:  83%|████████▎ | 5/6 [00:01<00:00,  4.82it/s]  4.32it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.06it/s]  4.32it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.06it/s]  4.32it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.06it/s]  4.32it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292      0.808      0.669      0.761      0.557██████| 6/6 [00:01<00:00,  5.06it/s]  4.32it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].32it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
     12/300      5.74G      1.177      1.222      1.223        100        640:  50%|█████     | 3/6 [00:00<00:00,  4.45it/s]  4.05it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
     12/300      5.74G      1.202      1.331      1.243         27        640: 100%|██████████| 6/6 [00:01<00:00,  4.98it/s]  4.05it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  4.98it/s]  4.05it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  4.98it/s]  4.05it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292      0.851       0.57      0.741      0.542██████| 6/6 [00:01<00:00,  4.98it/s]  4.05it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.96it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
     16/300      5.72G      1.157      1.001      1.159         60        640: 100%|██████████| 6/6 [00:01<00:00,  5.19it/s]  3.96it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.19it/s]  3.96it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.19it/s]  3.96it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292       0.98      0.489      0.737      0.526██████| 6/6 [00:01<00:00,  5.19it/s]  3.96it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.58it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
     20/300      5.49G      1.192      1.009      1.224         19        640: 100%|██████████| 6/6 [00:01<00:00,  5.11it/s]  3.93it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.11it/s]  3.93it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.11it/s]  3.93it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292      0.868      0.521      0.716      0.516██████| 6/6 [00:01<00:00,  5.11it/s]  3.93it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].93it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
     24/300      5.61G      1.184     0.8678      1.091        126        640:  17%|█▋        | 1/6 [00:00<00:01,  4.91it/s]  3.79it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
     24/300      5.61G      1.083     0.8514      1.097         28        640: 100%|██████████| 6/6 [00:01<00:00,  5.42it/s]  3.79it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.42it/s]  3.79it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.42it/s]  3.79it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292      0.947       0.76      0.854      0.662██████| 6/6 [00:01<00:00,  5.42it/s]  3.79it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292      0.947       0.76      0.854      0.662██████| 6/6 [00:01<00:00,  5.42it/s]  3.79it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  4.09it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
     28/300      5.75G      1.043      0.808      1.137         24        640: 100%|██████████| 6/6 [00:01<00:00,  5.34it/s]  4.09it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.34it/s]  4.09it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.34it/s]  4.09it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292      0.993      0.752      0.874      0.676██████| 6/6 [00:01<00:00,  5.34it/s]  4.09it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.47it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  0%|          | 0/6 [00:00<?, ?it/s]stances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.72it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
     32/300      5.84G      0.979     0.6847      1.051         21        640: 100%|██████████| 6/6 [00:01<00:00,  5.02it/s]  3.72it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.02it/s]  3.72it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.02it/s]  3.72it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292      0.939      0.878       0.93      0.733██████| 6/6 [00:01<00:00,  5.02it/s]  3.72it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292      0.939      0.878       0.93      0.733██████| 6/6 [00:01<00:00,  5.02it/s]  3.72it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.14it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
     36/300      5.87G      1.086     0.7415      1.137         29        640: 100%|██████████| 6/6 [00:01<00:00,  5.52it/s]  3.14it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.52it/s]  3.14it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.52it/s]  3.14it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292      0.994      0.804      0.899      0.727██████| 6/6 [00:01<00:00,  5.52it/s]  3.14it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.28it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
     40/300      5.73G     0.8591     0.6321      1.059         72        640:  33%|███▎      | 2/6 [00:00<00:00,  4.28it/s]  3.66it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
     40/300      5.73G     0.9408     0.6591      1.079         33        640: 100%|██████████| 6/6 [00:01<00:00,  4.94it/s]  3.66it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  4.94it/s]  3.66it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  4.94it/s]  3.66it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292      0.993      0.852      0.923      0.741██████| 6/6 [00:01<00:00,  4.94it/s]  3.66it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].66it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
     44/300      5.76G     0.8879     0.6154      1.055         74        640:  67%|██████▋   | 4/6 [00:00<00:00,  5.12it/s]  4.17it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
     44/300      5.76G     0.9058     0.6058      1.042         38        640: 100%|██████████| 6/6 [00:01<00:00,  5.52it/s]  4.17it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.52it/s]  4.17it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.52it/s]  4.17it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292      0.998      0.849      0.923      0.769██████| 6/6 [00:01<00:00,  5.52it/s]  4.17it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.68it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
     48/300       2.1G      1.021     0.6238      1.076        131        640:  17%|█▋        | 1/6 [00:00<00:01,  3.73it/s]  2.93it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
     48/300      5.73G     0.9216     0.6051       1.09         23        640: 100%|██████████| 6/6 [00:01<00:00,  4.91it/s]  2.93it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  4.91it/s]  2.93it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  4.91it/s]  2.93it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  4.91it/s]  2.93it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292      0.988      0.913      0.953      0.807██████| 6/6 [00:01<00:00,  4.91it/s]  2.93it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.11it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
     52/300      5.87G     0.9157      0.655      1.046         14        640: 100%|██████████| 6/6 [00:01<00:00,  5.40it/s]  3.11it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.40it/s]  3.11it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.40it/s]  3.11it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292      0.981       0.93      0.962      0.804██████| 6/6 [00:01<00:00,  5.40it/s]  3.11it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].11it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
     56/300      5.87G     0.9208     0.6716      1.063         90        640:  17%|█▋        | 1/6 [00:00<00:01,  4.40it/s]  3.00it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
     56/300      5.87G     0.8397     0.5874      1.008         37        640: 100%|██████████| 6/6 [00:01<00:00,  4.99it/s]  3.00it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  4.99it/s]  3.00it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  4.99it/s]  3.00it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292      0.998      0.931      0.964      0.818██████| 6/6 [00:01<00:00,  4.99it/s]  3.00it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292      0.998      0.931      0.964      0.818██████| 6/6 [00:01<00:00,  4.99it/s]  3.00it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.54it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
     60/300      5.87G     0.8335     0.5607      1.011         30        640: 100%|██████████| 6/6 [00:01<00:00,  5.62it/s]  3.54it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.62it/s]  3.54it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.62it/s]  3.54it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.62it/s]  3.54it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292      0.976       0.91      0.946      0.816██████| 6/6 [00:01<00:00,  5.62it/s]  3.54it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  0%|          | 0/6 [00:00<?, ?it/s]stances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.19it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
     64/300      5.74G     0.7522      0.542     0.9858         38        640: 100%|██████████| 6/6 [00:01<00:00,  5.05it/s]  3.19it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.05it/s]  3.19it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.05it/s]  3.19it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292      0.984      0.914      0.955      0.811██████| 6/6 [00:01<00:00,  5.05it/s]  3.19it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292      0.984      0.914      0.955      0.811██████| 6/6 [00:01<00:00,  5.05it/s]  3.19it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.92it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.31it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
     68/300      5.83G     0.7545     0.5228      1.007         84        640:  67%|██████▋   | 4/6 [00:00<00:00,  4.77it/s]  3.31it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
     68/300      5.83G     0.7534     0.5299      1.004         28        640: 100%|██████████| 6/6 [00:01<00:00,  5.22it/s]  3.31it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.22it/s]  3.31it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.22it/s]  3.31it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.22it/s]  3.31it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size: 100%|██████████| 6/6 [00:01<00:00,  5.22it/s]  3.31it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.75it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.75it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.75it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.75it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.75it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].75it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].75it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].75it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.72it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.72it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.72it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.72it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.72it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.81it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.81it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.81it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.976      0.985      0.869:  33%|███▎      | 1/3 [00:00<00:00,  2.81it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].81it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].81it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].81it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.78it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.78it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.78it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292      0.998       0.97      0.981      0.869:  33%|███▎      | 1/3 [00:00<00:00,  2.78it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].78it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].78it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].78it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].78it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].78it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.13it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.13it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.13it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292      0.992      0.977      0.984      0.879:  67%|██████▋   | 2/3 [00:00<00:00,  3.13it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.62it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.62it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.62it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].62it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].62it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].62it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.05it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.05it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.05it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.05it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.05it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.05it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.05it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.05it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.982      0.987      0.902:  33%|███▎      | 1/3 [00:00<00:00,  3.05it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.982      0.987      0.902:  33%|███▎      | 1/3 [00:00<00:00,  3.05it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.982      0.987      0.902:  33%|███▎      | 1/3 [00:00<00:00,  3.05it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.06it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.06it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.06it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.06it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.06it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.06it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.06it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.06it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.06it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.06it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.78it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.78it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.78it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.78it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.78it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.78it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.78it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.78it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.78it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.984      0.988        0.9:  33%|███▎      | 1/3 [00:00<00:00,  2.78it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.35it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.35it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.35it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.984      0.988      0.905:  67%|██████▋   | 2/3 [00:00<00:00,  3.35it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].35it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].35it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].35it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].35it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].35it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.87it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
    123/300      5.82G     0.5889     0.3934      0.922        102        640:  67%|██████▋   | 4/6 [00:00<00:00,  5.23it/s]  3.87it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
    123/300      5.82G     0.5889     0.3934      0.922        102        640:  67%|██████▋   | 4/6 [00:00<00:00,  5.23it/s]  3.87it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.79it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.79it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.79it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.988      0.989      0.927:  33%|███▎      | 1/3 [00:00<00:00,  2.79it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.988      0.989      0.927:  33%|███▎      | 1/3 [00:00<00:00,  2.79it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.988      0.989      0.927:  33%|███▎      | 1/3 [00:00<00:00,  2.79it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.82it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.82it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.82it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.988      0.989       0.92:  33%|███▎      | 1/3 [00:00<00:00,  2.82it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].82it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].82it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].82it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.94it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.94it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.94it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].94it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].94it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].94it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].94it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].94it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].94it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].94it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].94it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.06it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.06it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].06it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].06it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].06it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].06it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].06it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].06it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].06it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].06it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].06it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].06it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.84it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.84it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.84it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].84it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].84it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.933:  67%|██████▋   | 2/3 [00:00<00:00,  3.04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.94it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.94it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.94it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.96it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.96it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.96it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.72it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.72it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.72it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.942:  67%|██████▋   | 2/3 [00:00<00:00,  2.72it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].72it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].72it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].72it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].72it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].72it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99       0.95:   0%|          | 0/3 [00:00<?, ?it/s].72it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99       0.95:   0%|          | 0/3 [00:00<?, ?it/s].72it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99       0.95:   0%|          | 0/3 [00:00<?, ?it/s].72it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size       0.95:   0%|          | 0/3 [00:00<?, ?it/s].72it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size       0.95:   0%|          | 0/3 [00:00<?, ?it/s].72it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.03it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.03it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.75it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.75it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.75it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.75it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.75it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.75it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.988      0.989      0.949:  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.94it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.94it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.94it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.94it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.94it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.94it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.953:  33%|███▎      | 1/3 [00:00<00:00,  2.94it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.05it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.05it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.05it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.07it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.07it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.07it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.07it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.07it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.964:  67%|██████▋   | 2/3 [00:00<00:00,  3.04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.968:  67%|██████▋   | 2/3 [00:00<00:00,  3.04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.968:  67%|██████▋   | 2/3 [00:00<00:00,  3.04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.968:  67%|██████▋   | 2/3 [00:00<00:00,  3.04it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.89it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.89it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.89it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.07it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.07it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.07it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.963:  33%|███▎      | 1/3 [00:00<00:00,  3.07it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].07it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].07it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].07it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.968:  33%|███▎      | 1/3 [00:00<00:00,  3.01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.46it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.46it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.46it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.46it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.46it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].46it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].46it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].46it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].46it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].46it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.19it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
    225/300      5.83G     0.4052     0.2909     0.8534        124        640:  83%|████████▎ | 5/6 [00:01<00:00,  4.89it/s]  3.19it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
    225/300      5.83G     0.4052     0.2909     0.8534        124        640:  83%|████████▎ | 5/6 [00:01<00:00,  4.89it/s]  3.19it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].19it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].19it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.21it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.21it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.21it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.973:  67%|██████▋   | 2/3 [00:00<00:00,  3.21it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].21it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].21it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].21it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].21it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].21it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].21it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.974:  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.93it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.93it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.93it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.976:  33%|███▎      | 1/3 [00:00<00:00,  2.93it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.59it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.59it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.59it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.978:  33%|███▎      | 1/3 [00:00<00:00,  2.59it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].59it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].59it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].59it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.67it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.67it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.67it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.979:  67%|██████▋   | 2/3 [00:00<00:00,  2.67it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.979:  67%|██████▋   | 2/3 [00:00<00:00,  2.67it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.979:  67%|██████▋   | 2/3 [00:00<00:00,  2.67it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.97it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.97it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.97it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.02it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.02it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.02it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.13it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.13it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  3.13it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.982:  67%|██████▋   | 2/3 [00:00<00:00,  3.13it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.982:  67%|██████▋   | 2/3 [00:00<00:00,  3.13it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.982:  67%|██████▋   | 2/3 [00:00<00:00,  3.13it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.983:  67%|██████▋   | 2/3 [00:00<00:00,  3.13it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].13it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].13it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.97it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.97it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.97it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.983:  33%|███▎      | 1/3 [00:00<00:00,  2.97it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.983:  33%|███▎      | 1/3 [00:00<00:00,  2.97it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.983:  33%|███▎      | 1/3 [00:00<00:00,  2.97it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.983:  33%|███▎      | 1/3 [00:00<00:00,  2.97it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.983:  33%|███▎      | 1/3 [00:00<00:00,  2.97it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                   all        130        292          1      0.989       0.99      0.984:  33%|███▎      | 1/3 [00:00<00:00,  3.01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  3.01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].01it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.77it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.77it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.77it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].77it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].77it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].77it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].77it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].77it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].77it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].77it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].77it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.77it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.77it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.77it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.77it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.77it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.77it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.77it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.71it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.71it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  67%|██████▋   | 2/3 [00:00<00:00,  2.71it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.91it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.90it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.90it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size  mAP50-95):  33%|███▎      | 1/3 [00:00<00:00,  2.90it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].90it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].90it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].90it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].90it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].90it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].90it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].90it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
Validating runs/detect/train3/weights/best.pt...  Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s].90it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
              stranger        130         79          1          1      0.995      0.981:   0%|          | 0/3 [00:00<?, ?it/s].90it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
              stranger        130         79          1          1      0.995      0.981:   0%|          | 0/3 [00:00<?, ?it/s].90it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
0: 480x640 1 ashmit, 1 glasses, 5.0ms     79          1          1      0.995      0.981:   0%|          | 0/3 [00:00<?, ?it/s].90it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
Speed: 0.8ms preprocess, 4.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)          | 0/3 [00:00<?, ?it/s].90it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
Speed: 0.7ms preprocess, 5.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.5ms
Speed: 0.8ms preprocess, 4.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)          | 0/3 [00:00<?, ?it/s].90it/s]ll of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
0: 480x640 1 ashmit, 1 glasses, 4.5ms
Speed: 0.7ms preprocess, 4.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.2ms
Speed: 0.6ms preprocess, 4.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.6ms
Speed: 0.6ms preprocess, 4.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.7ms
Speed: 0.6ms preprocess, 4.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.4ms
Speed: 1.3ms preprocess, 4.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.6ms
Speed: 0.7ms preprocess, 4.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 5.2ms
Speed: 0.6ms preprocess, 5.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.4ms
Speed: 0.7ms preprocess, 4.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.3ms
Speed: 0.6ms preprocess, 3.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.2ms
Speed: 0.9ms preprocess, 4.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.6ms
Speed: 0.5ms preprocess, 3.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 5.1ms
Speed: 0.7ms preprocess, 5.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.7ms
Speed: 0.7ms preprocess, 4.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.8ms
Speed: 0.7ms preprocess, 3.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.1ms
Speed: 0.7ms preprocess, 4.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.6ms
Speed: 0.6ms preprocess, 4.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.8ms
Speed: 0.6ms preprocess, 3.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.6ms
Speed: 0.6ms preprocess, 4.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 5.1ms
Speed: 0.6ms preprocess, 5.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.7ms
Speed: 0.9ms preprocess, 4.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.2ms
Speed: 0.6ms preprocess, 4.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 5.8ms
Speed: 0.8ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.6ms
Speed: 0.7ms preprocess, 4.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.3ms
Speed: 0.5ms preprocess, 3.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.7ms
Speed: 0.7ms preprocess, 4.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.9ms
Speed: 0.7ms preprocess, 4.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 5.1ms
Speed: 0.7ms preprocess, 5.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.4ms
Speed: 0.7ms preprocess, 4.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.7ms
Speed: 0.7ms preprocess, 4.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.6ms
Speed: 0.6ms preprocess, 3.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.6ms
Speed: 0.5ms preprocess, 3.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.8ms
Speed: 1.0ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.5ms
Speed: 0.5ms preprocess, 3.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.2ms
Speed: 0.6ms preprocess, 3.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.3ms
Speed: 0.7ms preprocess, 4.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.9ms
Speed: 0.7ms preprocess, 4.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.8ms
Speed: 0.8ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.1ms
Speed: 0.5ms preprocess, 4.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.6ms
Speed: 0.6ms preprocess, 3.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.7ms
Speed: 0.6ms preprocess, 3.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.4ms
Speed: 0.6ms preprocess, 3.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.1ms
Speed: 0.6ms preprocess, 4.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.9ms
Speed: 0.5ms preprocess, 3.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.6ms
Speed: 0.6ms preprocess, 3.6ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.6ms
Speed: 0.6ms preprocess, 4.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.7ms
Speed: 0.6ms preprocess, 4.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.2ms
Speed: 1.1ms preprocess, 4.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.3ms
Speed: 0.7ms preprocess, 4.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.8ms
Speed: 0.7ms preprocess, 3.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.6ms
Speed: 0.6ms preprocess, 3.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.5ms
Speed: 0.6ms preprocess, 4.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.7ms
Speed: 0.8ms preprocess, 4.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.8ms
Speed: 0.7ms preprocess, 4.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.4ms
Speed: 0.6ms preprocess, 3.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.6ms
Speed: 0.7ms preprocess, 4.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.3ms
Speed: 0.5ms preprocess, 3.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.6ms
Speed: 0.5ms preprocess, 3.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 5.0ms
Speed: 0.7ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.7ms
Speed: 0.9ms preprocess, 3.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.7ms
Speed: 0.5ms preprocess, 3.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.2ms
Speed: 0.5ms preprocess, 4.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.7ms
Speed: 0.7ms preprocess, 3.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.2ms
Speed: 0.5ms preprocess, 3.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.2ms
Speed: 0.7ms preprocess, 4.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.5ms
Speed: 0.5ms preprocess, 3.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.3ms
Speed: 0.6ms preprocess, 3.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.5ms
Speed: 0.7ms preprocess, 4.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 5.2ms
Speed: 0.6ms preprocess, 5.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.3ms
Speed: 0.6ms preprocess, 4.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.3ms
Speed: 0.5ms preprocess, 4.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.3ms
Speed: 0.6ms preprocess, 3.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.6ms
Speed: 0.7ms preprocess, 4.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.5ms
Speed: 0.6ms preprocess, 3.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.1ms
Speed: 0.9ms preprocess, 4.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 2 ashmits, 1 glasses, 4.7ms
Speed: 0.7ms preprocess, 4.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 2 ashmits, 1 glasses, 3.9ms
Speed: 0.6ms preprocess, 3.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.2ms
Speed: 0.7ms preprocess, 4.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 2 ashmits, 1 glasses, 5.2ms
Speed: 0.6ms preprocess, 5.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 2 ashmits, 1 glasses, 4.3ms
Speed: 0.8ms preprocess, 4.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 2 ashmits, 1 glasses, 5.6ms
Speed: 0.7ms preprocess, 5.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.5ms
Speed: 0.7ms preprocess, 4.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.7ms
Speed: 0.7ms preprocess, 4.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 3.3ms
Speed: 0.7ms preprocess, 3.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.0ms
Speed: 0.6ms preprocess, 4.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 5.1ms
Speed: 0.8ms preprocess, 5.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.5ms
Speed: 0.7ms preprocess, 4.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 5.4ms
Speed: 0.7ms preprocess, 5.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 4.6ms
Speed: 0.6ms preprocess, 4.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 5.1ms
Speed: 0.9ms preprocess, 5.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 2 ashmits, 1 glasses, 4.8ms
Speed: 0.7ms preprocess, 4.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 2 ashmits, 1 glasses, 4.2ms
Speed: 0.7ms preprocess, 4.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 5.5ms
Speed: 0.7ms preprocess, 5.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 2 ashmits, 1 glasses, 3.2ms
Speed: 0.6ms preprocess, 3.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 2 ashmits, 1 glasses, 4.6ms
Speed: 0.7ms preprocess, 4.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)
0: 480x640 1 ashmit, 1 glasses, 6.6ms
Speed: 0.7ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)
image 1/1 /home/ashmitbhattarai/Codes/face_detection_model_family/data/images/test/IMG-2076.jpg: 480x640 1 ashmit, 1 glasses, 2 rameshs, 2 samjhus, 6.8ms
Speed: 2.3ms preprocess, 6.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)
image 1/1 /home/ashmitbhattarai/Codes/face_detection_model_family/data/images/test/IMG-2076.jpg: 480x640 1 ashmit, 1 glasses, 2 rameshs, 2 samjhus, 4.2ms
Speed: 1.5ms preprocess, 4.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)
image 1/1 /home/ashmitbhattarai/Codes/face_detection_model_family/data/images/test/IMG-2076.jpg: 480x640 2 alishmas, 1 ashmit, 1 glasses, 3 sabins, 5.1ms
